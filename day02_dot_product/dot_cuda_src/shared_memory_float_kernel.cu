// shared_memory_float_kernel.cu

#include <cuda_runtime.h>

#define THREADS 256  // í•˜ë‚˜ì˜ ë¸”ë¡ë‹¹ ì“°ë ˆë“œ ìˆ˜

// ì™¸ë¶€ì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•œ CUDA ì»¤ë„ í•¨ìˆ˜
extern "C"
__global__ void dotProductShared(const float* a, const float* b, float* result, int size) {
    // ë¸”ë¡ ë‚´ ê³µìœ  ë©”ëª¨ë¦¬ í• ë‹¹ (ë™ì¼ ë¸”ë¡ì˜ ì“°ë ˆë“œ ê°„ ë°ì´í„° ê³µìœ ìš©)
    __shared__ float cache[THREADS];

    // ì „ì²´ ê¸€ë¡œë²Œ ì¸ë±ìŠ¤ ê³„ì‚°: threadIdx + blockIdx * blockDim
    int tid = threadIdx.x + blockIdx.x * blockDim.x;

    // ê³µìœ  ë©”ëª¨ë¦¬ ë‚´ ì¸ë±ìŠ¤ (í˜„ì¬ ì“°ë ˆë“œì˜ ìœ„ì¹˜)
    int cacheIdx = threadIdx.x;

    float temp = 0.0f;
    /*
    blockDim.x: í•œ ë¸”ë¡ ì•ˆì˜ ì“°ë ˆë“œ ìˆ˜
    gridDim.x: ì „ì²´ ë¸”ë¡ ìˆ˜
    ë”°ë¼ì„œ blockDim.x * gridDim.x: ì „ì²´ ì“°ë ˆë“œ ì´í•©

    âœ… Strided loop: í•œ ì“°ë ˆë“œê°€ ì²˜ë¦¬í•  ì¸ë±ìŠ¤ë¥¼ ì¼ì • ê°„ê²©ìœ¼ë¡œ ì í”„í•˜ë©° ë°˜ë³µ ì²˜ë¦¬
    ì˜ˆ: tid = 0 â†’ 512 â†’ 1024 ...  (blockDim.x * gridDim.x = ì „ì²´ ì“°ë ˆë“œ ìˆ˜)
    */
    while (tid < size) {
        temp += a[tid] * b[tid];  // ë²¡í„° ìš”ì†Œ ê³±ì…ˆ ëˆ„ì 
        tid += blockDim.x * gridDim.x;  // ë‹¤ìŒ ë£¨í”„ì—ì„œ ìê¸° ì°¨ë¡€ ì¸ë±ìŠ¤ ì í”„
    }

    // ê³µìœ  ë©”ëª¨ë¦¬ì— ê° ì“°ë ˆë“œì˜ ëˆ„ì  ê²°ê³¼ ì €ì¥
    cache[cacheIdx] = temp;

    // ëª¨ë“  ì“°ë ˆë“œê°€ ê³µìœ  ë©”ëª¨ë¦¬ ì‘ì„±ì„ ë§ˆì¹  ë•Œê¹Œì§€ ë™ê¸°í™”
    __syncthreads();

    /*
    âœ… ë³‘ë ¬ reduction ìˆ˜í–‰: ê³µìœ  ë©”ëª¨ë¦¬ì—ì„œ ê°’ì„ ì ˆë°˜ì”© í•©ì¹˜ë©° ì¤„ì—¬ë‚˜ê°

    cache[0] + cache[1] + cache[2] + ... + cache[255]
    â†’ ì´ ì „ì²´ í•©ì„ cache[0] í•˜ë‚˜ì— ì €ì¥í•˜ëŠ” ê²Œ ëª©ì .

    iê°’	ì—­í• 
    128	0~127ë²ˆ ì“°ë ˆë“œê°€ cache[i] += cache[i+128] ìˆ˜í–‰
    64	0~63ë²ˆ ì“°ë ˆë“œê°€ cache[i] += cache[i+64] ìˆ˜í–‰
    32	0~31ë²ˆ   ì“°ë ˆë“œê°€ cache[i] += cache[i+32] ìˆ˜í–‰
    ...	...
    1	0ë²ˆ ì“°ë ˆë“œê°€ cache[0] += cache[1] ìˆ˜í–‰

    âœ… ì‹œê°í™” ì˜ˆ (8ê°œ ì“°ë ˆë“œ ì˜ˆì‹œ)
    ì´ˆê¸° ìƒíƒœ (temp ê³„ì‚° í›„):
    cache = [1, 2, 3, 4, 5, 6, 7, 8]
    1ë‹¨ê³„: i = 4
    cache[0] += cache[4] â†’ 1+5 = 6
    cache[1] += cache[5] â†’ 2+6 = 8
    cache[2] += cache[6] â†’ 3+7 = 10
    cache[3] += cache[7] â†’ 4+8 = 12
    â†’ cache = [6, 8, 10, 12, 5, 6, 7, 8]

    2ë‹¨ê³„: i = 2
    cache[0] += cache[2] â†’ 6+10 = 16
    cache[1] += cache[3] â†’ 8+12 = 20
    â†’ cache = [16, 20, 10, 12, ...]

    3ë‹¨ê³„: i = 1
    cache[0] += cache[1] â†’ 16+20 = 36
    ê²°ê³¼: cache[0] == ì´í•© ğŸ‰

    */
    for (int i = blockDim.x / 2; i > 0; i >>= 1) {
        if (cacheIdx < i) {
            cache[cacheIdx] += cache[cacheIdx + i];
        }
        __syncthreads();  // ë§¤ ë‹¨ê³„ë§ˆë‹¤ ì“°ë ˆë“œ ë™ê¸°í™”
    }

    /*
    CUDAì—ì„œ ë¸”ë¡ ìˆ˜ëŠ” ë³´í†µ ì•„ë˜ì™€ ê°™ì´ ìë™ ê³„ì‚°ë˜ëŠ”ë°, test_runner.cuì—ì„œ ì•„ë˜ì²˜ëŸ¼ ì“°ì…¨ì£ :
    int blocks = (N + THREADS - 1) / THREADS;
    N = 1 << 20 â†’ 1,048,576 (ì´ ë°ì´í„° ê°œìˆ˜)
    THREADS = 256 â†’ í•œ ë¸”ë¡ë‹¹ ì“°ë ˆë“œ ìˆ˜
    ë”°ë¼ì„œ:
        blocks = (1048576 + 256 - 1) / 256 = 4096
    âœ… ê²°ë¡ 
        ì´ 4096ê°œì˜ ë¸”ë¡ì´ ìƒì„±ë©ë‹ˆë‹¤.
    ê·¸ë¦¬ê³  ê° ë¸”ë¡ì˜ threadIdx.x == 0 ì“°ë ˆë“œë§Œ cache[0]ì„ ì „ì—­ ê²°ê³¼ resultì— atomicAdd() í•©ë‹ˆë‹¤.

    ì¦‰, ì´ 4096ê°œì˜ atomicAdd() ì—°ì‚°ì´ ì‹¤í–‰ë˜ëŠ” ì…ˆì…ë‹ˆë‹¤.
    */

    // ë¸”ë¡ ë‚´ ì²« ë²ˆì§¸ ì“°ë ˆë“œê°€ ìµœì¢… ê²°ê³¼ë¥¼ ì „ì—­ ë©”ëª¨ë¦¬ì— atomic ë°©ì‹ìœ¼ë¡œ ì €ì¥
    if (cacheIdx == 0) // ë¸”ë¡ ë‚´ 0ë²ˆ ì“°ë ˆë“œë§Œ ì‹¤í–‰ (blockë‹¹ 1ê°œ)
    {
        // cache[0]: ë¸”ë¡ ì „ì²´ ì“°ë ˆë“œì˜ ë‚´ì  ëˆ„ì í•©
        // atomicAdd: ì—¬ëŸ¬ ë¸”ë¡ì´ ë™ì‹œì— ì ‘ê·¼í•´ë„ ì•ˆì „í•˜ê²Œ ì „ì—­ í•©ì‚°
        atomicAdd(result, cache[0]);  // ğŸ”¥ ë‹¨ í•˜ë‚˜ì˜ ì“°ë ˆë“œë§Œ result ì— ë”í•¨
    }

    /*
    1. ê° ì“°ë ˆë“œê°€ ìì‹ ì˜ ì—­í• ë§Œí¼ ë‚´ì  ê³„ì‚° (a[tid] * b[tid])
    2. ê³µìœ  ë©”ëª¨ë¦¬ (cache)ì— ê° ì“°ë ˆë“œ ê²°ê³¼ ì €ì¥
    3. __syncthreads() â†’ ë³‘ë ¬ reduction ìˆ˜í–‰
    4. ìµœì¢…ì ìœ¼ë¡œ cache[0]ì— ë¸”ë¡ ì „ì²´ í•©ê³„ê°€ ëª¨ì„
    5. cacheIdx == 0ì¸ ì“°ë ˆë“œë§Œ â†’ resultì— atomicAdd()
    */
}
